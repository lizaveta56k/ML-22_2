{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification. Linear models and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement Logistic Regression with l2 regularization using gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression loss:\n",
    "$$ L(w) = \\dfrac{1}{N}\\sum_{i=1}^N \\log(1 + e^{-\\langle w, x_i \\rangle y_i}) + \\frac{1}{2C} \\lVert w \\rVert^2  \\to \\min_w$$\n",
    "$$\\langle w, x_i \\rangle = \\sum_{j=1}^n w_{j}x_{ij} + w_{0},$$ $$ y_{i} \\in \\{-1, 1\\}$$ where $n$ is the number of features and $N$ is the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent step:\n",
    "$$w^{(t+1)} := w^{(t)} + \\dfrac{\\eta}{N}\\sum_{i=1}^N y_ix_i \\Big(1 - \\dfrac{1}{1 + exp(-\\langle w^{(t)}, x_i \\rangle y_i)}\\Big) - \\eta \\frac{1}{C} w,$$\n",
    "where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) into \"even\" and \"odd\" categories. \"Even\" and \"Odd\" classes  should correspond to {-1, 1} labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping criteria: either the number of iterations exceeds *max_iter* or $||w^{(t+1)} - w^{(t)}||_2 < tol$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, eta=0.001, max_iter=1000, C=1.0, tol=1e-5, random_state=42, zero_init=False):\n",
    "        \"\"\"Logistic Regression classifier.\n",
    "        \n",
    "        Args:\n",
    "            eta: float, default=0.001\n",
    "                Learning rate.\n",
    "            max_iter: int, default=1000\n",
    "                Maximum number of iterations taken for the solvers to converge.\n",
    "            C: float, default=1.0\n",
    "                Inverse of regularization strength; must be a positive float.\n",
    "                Smaller values specify stronger regularization.\n",
    "            tol: float, default=1e-5\n",
    "                Tolerance for stopping criteria.\n",
    "            random_state: int, default=42\n",
    "                Random state.\n",
    "            zero_init: bool, default=False\n",
    "                Zero weight initialization.\n",
    "        \"\"\"\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.random_state = np.random.RandomState(seed=random_state)\n",
    "        self.zero_init = zero_init\n",
    "         \n",
    "    def get_sigmoid(self, X, weights):\n",
    "        \"\"\"Compute the sigmoid value.\"\"\"\n",
    "        return 1 / (1 + np.exp(-X @ weights.T))\n",
    "    \n",
    "#     def get_loss(self, x, weights, y):\n",
    "#         \"\"\"Calculate the loss.\"\"\"\n",
    "#         n = x.shape[0]\n",
    "# #         loss  = -(1 / n) * np.sum(y * np.log(self.get_sigmoid(x, weights)) + (1 - y) * np.log(\n",
    "# #             1 - self.get_sigmoid(x, weights)))\n",
    "#         sum = 0\n",
    "#         for i in range(n):\n",
    "#             sum += np.log(1 + np.exp(-(np.sum(x[i] @ weights[1:]) + weights[0]) * y[i])) \n",
    "            \n",
    "#         loss  = (1 / n) * sum + LA.norm(weights)/(2* self.C)\n",
    "#         return loss\n",
    "     \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X]) # a constant feature is included to handle intercept\n",
    "        num_features = X_ext.shape[1]\n",
    "        if self.zero_init:\n",
    "            self.weights_ = np.zeros(num_features) \n",
    "        else:\n",
    "            weight_threshold = 1.0 / (2 * num_features)\n",
    "            self.weights_ = self.random_state.uniform(low=-weight_threshold,\n",
    "                                                      high=weight_threshold, size=num_features) # random weight initialization\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            # Need to check this code\n",
    "            sum = 0\n",
    "            n = X_ext.shape[0]\n",
    "            for j in range(n):\n",
    "                sum += y[j] * X_ext[j] * (1 - 1/(1 + np.exp(-(np.sum(self.weights_.T @ X_ext[j])) * y[j]))) \n",
    "            delta = sum/n - self.weights_ / self.C\n",
    "            delta = -delta\n",
    "            \n",
    "            self.weights_ -= self.eta * delta\n",
    "            if self.max_iter or np.lilang.norm(self.weights_ - self.zero_init) < self.tol:\n",
    "                break\n",
    "     \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        if hasattr(self, 'weights_'):\n",
    "            return self.get_sigmoid(X_ext, self.weights_)\n",
    "        else: \n",
    "            raise NotFittedError(\"CustomLogisticRegression instance is not fitted yet\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        #normalise data using min_max scaling\n",
    "#         scaler = MinMaxScaler()\n",
    "#         scaler.fit(X)\n",
    "#         X = scaler.transform(X)\n",
    "\n",
    "        preds = self.predict_proba(X)\n",
    "        return [1 if i >= 0.5 else -1 for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 21 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "_, axes = plt.subplots(nrows=3, ncols=7, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "y_train = (y_train % 2) * 2 - 1\n",
    "y_test = (y_test % 2) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.unique(y_train) == [-1, 1]).all()\n",
    "assert (np.unique(y_test) == [-1, 1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    disp = metrics.plot_confusion_matrix(clf, X_test, y_test, normalize='true')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics.accuracy_score(y_pred=clf.predict(X_train), y_true=y_train), \\\n",
    "           metrics.accuracy_score(y_pred=clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = CustomLogisticRegression(max_iter=1, zero_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.get_sigmoid(np.array([[0.5, 0, 1.0], [0.3, 1.3, 1.0]]), np.array([0.5, -0.5, 0.1])),\n",
    "                   np.array([0.58662, 0.40131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.weights_, np.array([ 3.1000e-06,  0.0000e+00,  4.1800e-05,  5.4770e-04,  2.2130e-04,\n",
    "        4.8750e-04,  1.3577e-03,  5.9780e-04,  5.6400e-05, -7.0000e-07,\n",
    "        1.6910e-04,  2.5190e-04, -4.3700e-04,  3.6190e-04,  1.0049e-03,\n",
    "        4.2280e-04,  2.5700e-05,  3.0000e-07, -1.1500e-05, -7.2440e-04,\n",
    "       -2.6200e-04,  8.7540e-04,  4.1540e-04, -8.4200e-05, -5.2000e-06,\n",
    "        0.0000e+00, -2.2160e-04, -5.7130e-04,  9.8570e-04,  1.3507e-03,\n",
    "        5.0210e-04, -1.7050e-04, -1.0000e-06,  0.0000e+00, -6.7810e-04,\n",
    "       -1.0515e-03, -4.4500e-05,  3.7160e-04,  4.2100e-04, -8.1800e-05,\n",
    "        0.0000e+00, -5.2000e-06, -5.3410e-04, -2.0393e-03, -8.4310e-04,\n",
    "        1.0400e-04, -1.2390e-04, -1.7880e-04, -1.3200e-05, -4.5000e-06,\n",
    "       -9.4300e-05, -1.1127e-03, -5.0900e-04, -2.1850e-04, -5.6050e-04,\n",
    "       -3.9560e-04, -1.7700e-05, -3.0000e-07,  2.6800e-05,  6.3920e-04,\n",
    "        1.8090e-04, -7.3660e-04, -5.3930e-04, -3.7060e-04, -2.8200e-05]), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5894224077940153, 0.6027777777777777)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11044/4215115562.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert min(train_acc, test_acc) > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Visualize the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different learning rates and compare the results. How does the learning rate influence the convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different regularization parameter values and compare the model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare zero initialization and random initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement weighted K-Neighbors Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that training a KNN classifier is simply memorizing a training sample. \n",
    "\n",
    "The process of applying a classifier for one object is to find the distances from it to all objects in the training data, then select the k nearest objects (neighbors) and return the most common class among these objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also give the nearest neighbors weights in accordance with the distance of the object to them. In the simplest case (as in your assignment), you can set the weights inversely proportional to that distance. \n",
    "\n",
    "$$w_{i} = \\frac{1}{d_{i} + eps},$$\n",
    "\n",
    "where $d_{i}$ is the distance between object and i-th nearest neighbor and $eps$ is the small value to prevent division by zero.\n",
    "\n",
    "In case of 'uniform' weights, all k nearest neighbors are equivalent (have equal weight, for example $w_{i} = 1, \\forall i \\in(1,k)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the probability of classes, it is necessary to normalize the weights of each class, dividing them by the sum:\n",
    "\n",
    "$$p_{i} = \\frac{w_{i}}{\\sum_{j=1}^{c}w_{j}},$$\n",
    "\n",
    "where $p_i$ is probability of i-th class and $c$ is the number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits. By implementing this algorithm, you will be able to classify numbers not only into \"even\" or \"odd\", but into their real representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKNeighborsClassifier:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, n_neighbors=5, weights='uniform', eps=1e-9):\n",
    "        \"\"\"K-Nearest Neighbors classifier.\n",
    "        \n",
    "        Args:\n",
    "            n_neighbors: int, default=5\n",
    "                Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
    "            weights : {'uniform', 'distance'} or callable, default='uniform'\n",
    "                Weight function used in prediction.  Possible values:\n",
    "                - 'uniform' : uniform weights.  All points in each neighborhood\n",
    "                  are weighted equally.\n",
    "                - 'distance' : weight points by the inverse of their distance.\n",
    "                  in this case, closer neighbors of a query point will have a\n",
    "                  greater influence than neighbors which are further away.\n",
    "            eps : float, default=1e-5\n",
    "                Epsilon to prevent division by 0 \n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.eps = eps\n",
    "        \n",
    "    \n",
    "    def get_pairwise_distances(self, X, Y):\n",
    "        \"\"\"\n",
    "        Returnes matrix of the pairwise distances between the rows from both X and Y.\n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            Y: numpy array of shape (k_samples, n_features)\n",
    "        Returns:\n",
    "            P: numpy array of shape (n_samples, k_samples)\n",
    "                Matrix in which (i, j) value is the distance \n",
    "                between i'th row from the X and j'th row from the Y.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def get_class_weights(self, y, weights):\n",
    "        \"\"\"\n",
    "        Returns a vector with sum of weights for each class \n",
    "        Args:\n",
    "            y: numpy array of shape (n_samles,)\n",
    "            weights: numpy array of shape (n_samples,)\n",
    "                The weights of the corresponding points of y.\n",
    "        Returns:\n",
    "            p: numpy array of shape (n_classes)\n",
    "                Array where the value at the i-th position \n",
    "                corresponds to the weight of the i-th class.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass\n",
    "            \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        self.points = X\n",
    "        self.y = y\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples, n_classes)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'points'):\n",
    "            P = self.get_pairwise_distances(X, self.points)\n",
    "            \n",
    "            weights_of_points = np.ones(P.shape)\n",
    "            if self.weights == 'distance':\n",
    "                weights_of_points = 'your code'\n",
    "                \n",
    "            # <your code>\n",
    "            pass\n",
    "        \n",
    "        else: \n",
    "            raise NotFittedError(\"CustomKNeighborsClassifier instance is not fitted yet\")\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomKNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(model.get_pairwise_distances(np.array([[0  , 1]  , [1, 1]]), \n",
    "                                                np.array([[0.5, 0.5], [1, 0]])),\n",
    "                   np.array([[0.70710678, 1.41421356],\n",
    "                             [0.70710678, 1.        ]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_ = ['one', 'two', 'three']\n",
    "assert np.allclose(model.get_class_weights(np.array(['one', 'one', 'three', 'two']), np.array([1, 1, 0, 4])), \n",
    "                   np.array([2,4,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "_, axes = plt.subplots(nrows=3, ncols=7, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "knn.fit(X_train, list(map(str, y_train)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(model.predict_proba(X_test), knn.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc == 1\n",
    "assert test_acc > 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Take a look at the confusion matrix and tell what numbers the model confuses and why this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different n_neighbors parameters and compare the output probabilities of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare both 'uniform' and 'distance' weights and share your thoughts in what situations which parameter can be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest another distance measurement function that could improve the quality of the classification for this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest different task and distance function that you think would be suitable for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Synthetic Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Read the description here: https://www.kaggle.com/c/tabular-playground-series-apr-2021/data. Download the dataset and place it in the *data/titanic/* folder in your working directory.\n",
    "You will use train.csv for model training and validation. The test set is used for model testing: once the model is trained, you can predict whether a passenger survived or not for each passenger in the test set, and submit the predictions: https://www.kaggle.com/c/tabular-playground-series-apr-2021/overview/evaluation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/train.csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(PATH, 'train.csv')).set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data_female = data[data['Sex'] == 'female']\n",
    "titanic_data_male = data[data['Sex'] == 'male']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** How many females and males are there in the dataset? What about the survived passengers? Is there any relationship between the gender and the survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count of male in the dataset: ' + str(data[data['Sex'] == 'male'].shape[0]))\n",
    "print('Count of female in the dataset: ' + str(data[data['Sex'] == 'female'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Sex').size().plot.pie(y='Sex',figsize=(5, 5),autopct='%1.1f%%', startangle=90) \\\n",
    ".set_title('Distribution of passengers by gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = data[data['Survived'] == 1].groupby('Sex').size()\n",
    "survived.plot.pie(y='Sex',figsize=(5, 5),autopct='%1.1f%%', startangle=90) \\\n",
    ".set_title('Distribution of survived passengers per Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что женщин выжило в 2 раза больше, значит пол очень сильно влиял на выживаемость. Скорее всего это из-за того, что спасали в первую очередь женщин и детей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Plot age distribution of the passengers. What is the average and the median age of survived and deceased passengers? Do age distributions differ for survived and deceased passengers? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Survived'] == 1]['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Survived'] == 0]['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.set_theme()\n",
    "sns.kdeplot(data=data['Age'], shade=True).set_title('Age distribution of the passengers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим из графика выше, наибольше количество пассажиров было в возрасте от 25 до 50.\n",
    "\n",
    "Самому старшему пассажиру было 87 лет. Самому младшему 0.08 лет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=data['Age'], y=data['Survived']).set_title('The relationship between Age and chance to survive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(data=data, x=\"Survived\", y=\"Age\", hue = \"Sex\").set_title('The relationship between Age, Sex and chance to survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возраст влиял на выживаемость, но намного меньше, чем пол."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cluster the ages by group and look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_age_status(x):\n",
    "    age=x['Age']\n",
    "    if age <= 2:\n",
    "        return 'Babies'\n",
    "    elif age <= 14:\n",
    "        return 'Children'\n",
    "    elif age <= 24:\n",
    "        return 'Youth'\n",
    "    elif age <= 60:\n",
    "        return 'Adults'\n",
    "    else:\n",
    "        return 'Seniors'\n",
    "    \n",
    "data['Age_Status'] = data.apply(add_age_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Sex', y ='Survived', hue='Age_Status', data = data).set(title='The relationship between Sex, Age status and chance to survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age did affect survival rates. We can see that the survival rate of women increased a bit with age, and vice versa for men. However, a lot of men were survived even though they should have been the last to be rescued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 point)** Explore \"passenger class\" and \"embarked\" features. What class was \"the safest\"? Is there any relationship between the embarkation port and the survival? Provide the corresponding visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Pclass').size().plot.pie(y='Pclass',figsize=(5, 5),autopct='%1.1f%%', startangle=90) \\\n",
    ".set_title('Distribution of passengers by Pclass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Embarked').size().plot.pie(y='Embarked',figsize=(5, 5),autopct='%1.1f%%', startangle=90).set_title('Distribution of Port of Embarkation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.barplot(x = 'Pclass', y ='Survived', data = data).set_title('The relationship between Pclass and chance to survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can see that the higher the class, the higher the probability of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Age\", y=\"Pclass\", hue=\"Survived\", data=titanic_data_female).set(title='The relationship between Pclass, Age and survival status for women')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Age\", y=\"Pclass\", hue=\"Survived\", data=titanic_data_male).set(title='The relationship between Pclass, Age and survival status for men')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs above, we see that the chance of survival for women in first and second class is much higher.\n",
    "\n",
    "Выглядит немного странно, потому что выжили почти все мужчины из первого класса в возрасте 60-80 лет. Детей же мужского пола не выжило значительно больше для всех классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.lineplot(x='Embarked', y='Survived', data=data).set(title='The relationship between port of landing and chance to survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, you might notice that those who departed from the port of Cherbourg had the best chance of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "sns.jointplot(\n",
    "    data=data,\n",
    "    x=\"Pclass\", y=\"Survived\", hue=\"Embarked\",\n",
    "    kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows that the relationship between port of landing and survivability arose because of the port/class relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый класс существенно улучшал выживаемость, порт посадки тоже имел какое-то воздествие, но в первую очередь из-за того, что некоторые классы садились в определенных портах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Find the percentage of missing values for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = data.isnull().sum() * 100 / len(data)\n",
    "missing_value_df = pd.DataFrame({'column': data.columns, '% missing': percent_missing})\n",
    "\n",
    "print(missing_value_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Is_Deck_Unknown']=data['Deck'] == 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.barplot(x = 'Is_Deck_Unknown', y ='Survived', data = data).set(title='The relationship between Is_Deck_Unknown and chance to survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that people whose cabin numbers are known have a better chance of survival. This could be because the stateroom number was reported by surviving passengers after the crash.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the ways to handle these missing values for modelling and write your answer below. Which methods would you suggest? What are their advantages and disadvantages?\n",
    "\n",
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть несколько вариантов, как избавиться от пустых значений:\n",
    "\n",
    "        1) Просто удалить записи, где есть пустые колонки Age, Ticket, Fare, Embarked. Данных много, а процент пропусков небольшой, поэтому это может быть вполне себе приемлимый вариант. Однако могут быть какие-то важные зависимости от того заполнены ли какие-то данные или нет (как на графике выше)\n",
    "        \n",
    "        2) Заполнить средними значениями. Вариант не сильно лучше пердыдущего в данном случае. Пользы от таких данных будет не сильно много.\n",
    "        \n",
    "        3) Найти какие-то зависимости, разбить данные на кластеры и заполнить. Лучший варинт, но наиболее времязатратный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 points)** Prepare the features and train two models (KNN and Logistic Regression) to predict the survival. Compare the results. Use accuracy as a metric. Don't forget about cross-validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим новые фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Family_Size']=data['SibSp']+data['Parch']\n",
    "data['Fare_Per_Person']=data['Fare']/(data['Family_Size']+1)\n",
    "data['Is_Family_On_Board']=data['Family_Size'] > 0\n",
    "\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    res = list(filter(lambda x:  x in big_string , substrings))\n",
    "    return str(res[0]) if res else 'Unknown'\n",
    "\n",
    "def titles_in_name(big_string, substrings):\n",
    "    res = list(filter(lambda x: bool(re.search(r\"\\b(\" + x + r\"\\.)\\s\", big_string)), substrings))\n",
    "    return str(res[0]) if res else 'Unknown'\n",
    "\n",
    "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "                    'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "                    'Don', 'Jonkheer', 'Lady', 'Sir']\n",
    "\n",
    "def replace_titles(x):\n",
    "    title=x['Title']\n",
    "    if title in ['Capt', 'Col', 'Don', 'Dr', 'Jonkheer', 'Lady', 'Major', 'Rev', 'Sir', 'Countess']:\n",
    "        return 'Aristocratic'\n",
    "    if title in ['Mlle', 'Mme']:\n",
    "        return 'Miss'\n",
    "    if title in ['Ms']:\n",
    "        return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n",
    "data['Deck']=data['Cabin'].map(lambda x: substrings_in_string(str(x), cabin_list))\n",
    "data['Title']=data['Name'].map(lambda x: titles_in_name(str(x), title_list))\n",
    "data['Title']=data.apply(replace_titles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 + X points)** Try more feature engineering and hyperparameter tuning to improve the results. You may use either KNN or Logistic Regression (or both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best model, load the test set and make the predictions. Submit them to kaggle and see the results :)\n",
    "\n",
    "**Note**. X points will depend on your kaggle public leaderboard score.\n",
    "$$ f(score) = 1.0, \\ \\ 0.79 \\leq score < 0.80,$$\n",
    "$$ f(score) = 2.5, \\ \\ 0.80 \\leq score < 0.81,$$ \n",
    "$$ f(score) = 4.0, \\ \\ 0.81 \\leq score $$ \n",
    "Your code should generate the output submitted to kaggle. Fix random seeds to make the results reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
